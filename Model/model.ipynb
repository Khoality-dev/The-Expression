{"cells":[{"cell_type":"markdown","metadata":{"id":"Y76axBV8GQo2"},"source":["## Import Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HXMjh8hNk9m"},"outputs":[],"source":["# List of external libraries used:\n","# pandas: https://pandas.pydata.org\n","# numpy: https://numpy.org\n","# matplotlub: https://matplotlib.org\n","# sklearn: https://scikit-learn.org"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1945,"status":"ok","timestamp":1648087550743,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"y42It3hMOFbe","outputId":"3372d661-967d-40d1-8ce9-e0b971472e51"},"outputs":[],"source":["# import os\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# os.chdir(\"drive/My Drive/Colab Notebooks/CMPT419Project/model\")"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13924,"status":"ok","timestamp":1648087564665,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"jhxzzOkz0fyX"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-24 15:50:31.385045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hvtruong/.local/lib/python3.8/site-packages/cv2/../../lib64:\n","2022-03-24 15:50:31.385121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n","  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","\n","from sklearn.utils import shuffle\n","\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AvgPool2D, Input, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model"]},{"cell_type":"markdown","metadata":{"id":"jTuCSBCUGbx9"},"source":["# Preprocessing:"]},{"cell_type":"markdown","metadata":{},"source":["## Landmarks detection"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import dlib\n","\n","predictor = dlib.shape_predictor('../Dataset/utils/shape_predictor_68_face_landmarks.dat')\n","\n","def get_landmarks(face):\n","    landmarks = predictor(face, dlib.rectangle(0,0,63,63))\n","    landmarks_image = np.zeros((64,64))\n","    for i in range(0, 68):\n","        cv2.circle(landmarks_image, (landmarks.part(i).x, landmarks.part(i).y), 1, 255, 1)\n","  \n","    return landmarks_image"]},{"cell_type":"markdown","metadata":{},"source":["## Load the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":32332,"status":"ok","timestamp":1648087596983,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"LvMPiJ8kNk9s"},"outputs":[],"source":["import h5py\n","\n","filename = \"../Dataset/facial_data/facial_data.h5\"\n","\n","data = np.zeros((25844,64,64,2))\n","\n","with h5py.File(filename, \"r\") as f:\n","    keys = list(f.keys())\n","    # Get the data\n","    for i in range(int(len(keys))):\n","      data[i,:,:,0] = (np.array(f[keys[i]]))\n","      data[i,:,:,1] = (get_landmarks(np.array(f[keys[i]])))\n","\n","data = np.array(data)\n","\n","df = pd.read_csv('../Dataset/src_data/label_data.csv')\n","df = df[df['file_name'].isin(keys)]\n","targets = df[['arousal', 'valence']].values\n","\n","data, targets = shuffle(data, targets)"]},{"cell_type":"markdown","metadata":{"id":"wbIA_jMgNk9y"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"viqiqZskQe9W"},"source":["## Model take input as gray images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["learning_rate = 0.0001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/grayImagesModel.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNWocgAuNk9y","outputId":"a11140eb-3d63-4c10-9b05-338f69e0c0ba"},"outputs":[],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 32x32x16\n","\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 16x16x32\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Dense(2, activation='linear'))\n","\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index]\n","    y_train = targets[train_index]\n","    x_val = data[val_index]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= (x_val, y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])\n","\n","model.save('./grayImagesModel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jbSh8y5Nk9z","outputId":"d83c9cb1-0801-409b-e1e6-6e0c66338276"},"outputs":[],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ju1K08ZBNk90","outputId":"9e3eae68-4b9e-463f-a282-841496a8a634"},"outputs":[],"source":["plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApVAp0TmNk91","outputId":"ef084cc5-fa39-4f1d-977b-fc96d66cdfe1"},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]},{"cell_type":"markdown","metadata":{"id":"jkLKmTOvoBUW"},"source":["## Model takes inputs as gray images with an addtional landmarks layer"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["learning_rate = 0.0001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/2layersInputModel.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-24 09:51:28.395375: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - ETA: 0s - loss: 6.6782"]},{"name":"stderr","output_type":"stream","text":["2022-03-24 09:54:11.606623: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 169377792 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["324/324 [==============================] - 169s 513ms/step - loss: 6.6782 - val_loss: 5.5290\n","Epoch 2/30\n","324/324 [==============================] - 155s 479ms/step - loss: 5.3150 - val_loss: 4.1967\n","Epoch 3/30\n","324/324 [==============================] - 156s 482ms/step - loss: 4.3613 - val_loss: 3.5326\n","Epoch 4/30\n","324/324 [==============================] - 154s 476ms/step - loss: 3.7010 - val_loss: 3.1867\n","Epoch 5/30\n","324/324 [==============================] - 153s 472ms/step - loss: 3.2701 - val_loss: 2.8422\n","Epoch 6/30\n","324/324 [==============================] - 151s 466ms/step - loss: 2.9136 - val_loss: 2.6661\n","Epoch 7/30\n","324/324 [==============================] - 136s 420ms/step - loss: 2.6933 - val_loss: 2.4939\n","Epoch 8/30\n","324/324 [==============================] - 136s 419ms/step - loss: 2.4867 - val_loss: 2.3353\n","Epoch 9/30\n","324/324 [==============================] - 137s 422ms/step - loss: 2.2398 - val_loss: 2.2458\n","Epoch 10/30\n","324/324 [==============================] - 136s 421ms/step - loss: 2.1306 - val_loss: 2.1253\n","Epoch 11/30\n","324/324 [==============================] - 136s 421ms/step - loss: 2.0240 - val_loss: 2.1295\n","Epoch 12/30\n","324/324 [==============================] - 137s 422ms/step - loss: 1.8653 - val_loss: 2.0095\n","Epoch 13/30\n","324/324 [==============================] - 136s 421ms/step - loss: 1.7788 - val_loss: 1.9630\n","Epoch 14/30\n","324/324 [==============================] - 136s 420ms/step - loss: 1.6547 - val_loss: 1.9729\n","Epoch 15/30\n","324/324 [==============================] - 137s 422ms/step - loss: 1.5986 - val_loss: 1.9332\n","Epoch 16/30\n","324/324 [==============================] - 143s 440ms/step - loss: 1.5235 - val_loss: 1.8909\n","Epoch 17/30\n","324/324 [==============================] - 138s 425ms/step - loss: 1.4272 - val_loss: 1.8518\n","Epoch 18/30\n","324/324 [==============================] - 138s 427ms/step - loss: 1.3925 - val_loss: 1.8342\n","Epoch 19/30\n","324/324 [==============================] - 137s 423ms/step - loss: 1.3208 - val_loss: 1.7658\n","Epoch 20/30\n","324/324 [==============================] - 137s 423ms/step - loss: 1.2782 - val_loss: 1.7717\n","Epoch 21/30\n","324/324 [==============================] - 137s 422ms/step - loss: 1.2387 - val_loss: 1.7561\n","Epoch 22/30\n","324/324 [==============================] - 137s 423ms/step - loss: 1.1867 - val_loss: 1.7447\n","Epoch 23/30\n","324/324 [==============================] - 159s 491ms/step - loss: 1.1214 - val_loss: 1.7517\n","Epoch 24/30\n","324/324 [==============================] - 164s 506ms/step - loss: 1.1094 - val_loss: 1.7450\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-24 10:49:12.862346: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - ETA: 0s - loss: 6.5295"]},{"name":"stderr","output_type":"stream","text":["2022-03-24 10:51:46.538131: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 169377792 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["324/324 [==============================] - 160s 489ms/step - loss: 6.5295 - val_loss: 5.6492\n","Epoch 2/30\n","324/324 [==============================] - 151s 465ms/step - loss: 5.1363 - val_loss: 4.4548\n","Epoch 3/30\n","324/324 [==============================] - 148s 457ms/step - loss: 4.1802 - val_loss: 3.4390\n","Epoch 4/30\n","324/324 [==============================] - 149s 461ms/step - loss: 3.5558 - val_loss: 3.1393\n","Epoch 5/30\n","324/324 [==============================] - 149s 460ms/step - loss: 3.1612 - val_loss: 2.7888\n","Epoch 6/30\n","324/324 [==============================] - 149s 459ms/step - loss: 2.8491 - val_loss: 2.6720\n","Epoch 7/30\n","324/324 [==============================] - 148s 458ms/step - loss: 2.5730 - val_loss: 2.4958\n","Epoch 8/30\n","324/324 [==============================] - 141s 436ms/step - loss: 2.4381 - val_loss: 2.4186\n","Epoch 9/30\n","324/324 [==============================] - 134s 414ms/step - loss: 2.2325 - val_loss: 2.2758\n","Epoch 10/30\n","324/324 [==============================] - 135s 417ms/step - loss: 2.1190 - val_loss: 2.1886\n","Epoch 11/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.9767 - val_loss: 2.1327\n","Epoch 12/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.8638 - val_loss: 2.1313\n","Epoch 13/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.7937 - val_loss: 2.1362\n","Epoch 14/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.6789 - val_loss: 1.9719\n","Epoch 15/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.6005 - val_loss: 1.9907\n","Epoch 16/30\n","324/324 [==============================] - 134s 414ms/step - loss: 1.5338 - val_loss: 1.9349\n","Epoch 17/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.4668 - val_loss: 1.9088\n","Epoch 18/30\n","324/324 [==============================] - 134s 415ms/step - loss: 1.3879 - val_loss: 1.8530\n","Epoch 19/30\n","324/324 [==============================] - 136s 418ms/step - loss: 1.3595 - val_loss: 1.8165\n","Epoch 20/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.2883 - val_loss: 1.7662\n","Epoch 21/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.2239 - val_loss: 1.7538\n","Epoch 22/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.2049 - val_loss: 1.7878\n","Epoch 23/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.1616 - val_loss: 1.7295\n","Epoch 24/30\n","324/324 [==============================] - 135s 415ms/step - loss: 1.1167 - val_loss: 1.7539\n","Epoch 25/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.0854 - val_loss: 1.7335\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-24 11:47:32.958777: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 137s 419ms/step - loss: 6.6398 - val_loss: 5.4804\n","Epoch 2/30\n","324/324 [==============================] - 135s 416ms/step - loss: 5.3207 - val_loss: 4.3035\n","Epoch 3/30\n","324/324 [==============================] - 134s 415ms/step - loss: 4.3062 - val_loss: 3.5966\n","Epoch 4/30\n","324/324 [==============================] - 134s 413ms/step - loss: 3.7149 - val_loss: 3.2500\n","Epoch 5/30\n","324/324 [==============================] - 135s 418ms/step - loss: 3.2756 - val_loss: 3.0410\n","Epoch 6/30\n","324/324 [==============================] - 134s 414ms/step - loss: 2.9554 - val_loss: 2.8521\n","Epoch 7/30\n","324/324 [==============================] - 134s 415ms/step - loss: 2.7016 - val_loss: 2.6310\n","Epoch 8/30\n","324/324 [==============================] - 135s 417ms/step - loss: 2.5100 - val_loss: 2.5397\n","Epoch 9/30\n","324/324 [==============================] - 136s 419ms/step - loss: 2.3343 - val_loss: 2.4633\n","Epoch 10/30\n","324/324 [==============================] - 135s 418ms/step - loss: 2.2115 - val_loss: 2.4029\n","Epoch 11/30\n","324/324 [==============================] - 135s 415ms/step - loss: 2.0633 - val_loss: 2.2961\n","Epoch 12/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.9405 - val_loss: 2.2521\n","Epoch 13/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.8664 - val_loss: 2.2447\n","Epoch 14/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.7845 - val_loss: 2.1810\n","Epoch 15/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.6899 - val_loss: 2.1728\n","Epoch 16/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.6312 - val_loss: 2.0999\n","Epoch 17/30\n","324/324 [==============================] - 135s 415ms/step - loss: 1.5535 - val_loss: 2.0977\n","Epoch 18/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.4939 - val_loss: 2.0017\n","Epoch 19/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.4206 - val_loss: 2.0182\n","Epoch 20/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.3605 - val_loss: 1.9961\n","Epoch 21/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.3023 - val_loss: 1.9631\n","Epoch 22/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.2691 - val_loss: 1.9929\n","Epoch 23/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.2476 - val_loss: 1.9316\n","Epoch 24/30\n","324/324 [==============================] - 135s 415ms/step - loss: 1.1921 - val_loss: 1.9483\n","Epoch 25/30\n","324/324 [==============================] - 136s 421ms/step - loss: 1.1505 - val_loss: 1.8852\n","Epoch 26/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.1154 - val_loss: 1.8622\n","Epoch 27/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.0949 - val_loss: 1.8757\n","Epoch 28/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.0583 - val_loss: 1.8686\n","Epoch 1/30\n","324/324 [==============================] - 136s 419ms/step - loss: 6.5830 - val_loss: 5.4289\n","Epoch 2/30\n","324/324 [==============================] - 135s 417ms/step - loss: 5.1008 - val_loss: 4.0155\n","Epoch 3/30\n","324/324 [==============================] - 135s 416ms/step - loss: 4.1302 - val_loss: 3.4322\n","Epoch 4/30\n","324/324 [==============================] - 136s 418ms/step - loss: 3.4833 - val_loss: 2.9891\n","Epoch 5/30\n","324/324 [==============================] - 135s 417ms/step - loss: 3.0697 - val_loss: 2.7891\n","Epoch 6/30\n","324/324 [==============================] - 134s 415ms/step - loss: 2.7871 - val_loss: 2.6697\n","Epoch 7/30\n","324/324 [==============================] - 135s 415ms/step - loss: 2.5260 - val_loss: 2.5628\n","Epoch 8/30\n","324/324 [==============================] - 134s 414ms/step - loss: 2.3153 - val_loss: 2.4229\n","Epoch 9/30\n","324/324 [==============================] - 140s 433ms/step - loss: 2.1697 - val_loss: 2.2160\n","Epoch 10/30\n","324/324 [==============================] - 141s 435ms/step - loss: 2.0213 - val_loss: 2.2171\n","Epoch 11/30\n","324/324 [==============================] - 134s 414ms/step - loss: 1.8888 - val_loss: 2.1244\n","Epoch 12/30\n","324/324 [==============================] - 134s 412ms/step - loss: 1.8043 - val_loss: 2.0354\n","Epoch 13/30\n","324/324 [==============================] - 134s 414ms/step - loss: 1.6793 - val_loss: 1.9989\n","Epoch 14/30\n","324/324 [==============================] - 133s 412ms/step - loss: 1.6123 - val_loss: 2.0336\n","Epoch 15/30\n","324/324 [==============================] - 133s 412ms/step - loss: 1.5425 - val_loss: 1.9414\n","Epoch 16/30\n","324/324 [==============================] - 133s 412ms/step - loss: 1.4515 - val_loss: 1.9298\n","Epoch 17/30\n","324/324 [==============================] - 135s 415ms/step - loss: 1.3887 - val_loss: 1.8239\n","Epoch 18/30\n","324/324 [==============================] - 134s 413ms/step - loss: 1.3402 - val_loss: 1.8807\n","Epoch 19/30\n","324/324 [==============================] - 134s 413ms/step - loss: 1.2972 - val_loss: 1.8571\n","Epoch 1/30\n","324/324 [==============================] - 137s 421ms/step - loss: 6.6447 - val_loss: 6.4026\n","Epoch 2/30\n","324/324 [==============================] - 135s 418ms/step - loss: 5.1781 - val_loss: 4.2165\n","Epoch 3/30\n","324/324 [==============================] - 136s 420ms/step - loss: 4.2161 - val_loss: 3.4405\n","Epoch 4/30\n","324/324 [==============================] - 135s 416ms/step - loss: 3.5226 - val_loss: 3.0569\n","Epoch 5/30\n","324/324 [==============================] - 135s 416ms/step - loss: 3.0969 - val_loss: 2.7874\n","Epoch 6/30\n","324/324 [==============================] - 135s 415ms/step - loss: 2.7932 - val_loss: 2.5783\n","Epoch 7/30\n","324/324 [==============================] - 135s 417ms/step - loss: 2.5261 - val_loss: 2.4176\n","Epoch 8/30\n","324/324 [==============================] - 135s 418ms/step - loss: 2.3553 - val_loss: 2.3630\n","Epoch 9/30\n","324/324 [==============================] - 135s 417ms/step - loss: 2.1849 - val_loss: 2.3103\n","Epoch 10/30\n","324/324 [==============================] - 136s 418ms/step - loss: 2.0424 - val_loss: 2.2027\n","Epoch 11/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.8925 - val_loss: 2.1576\n","Epoch 12/30\n","324/324 [==============================] - 136s 420ms/step - loss: 1.8176 - val_loss: 2.0522\n","Epoch 13/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.7223 - val_loss: 2.0014\n","Epoch 14/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.6138 - val_loss: 1.9521\n","Epoch 15/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.5690 - val_loss: 1.9985\n","Epoch 16/30\n","324/324 [==============================] - 136s 418ms/step - loss: 1.4904 - val_loss: 1.9200\n","Epoch 17/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.4202 - val_loss: 1.9267\n","Epoch 18/30\n","324/324 [==============================] - 136s 420ms/step - loss: 1.3762 - val_loss: 1.8774\n","Epoch 19/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.3035 - val_loss: 1.8872\n","Epoch 20/30\n","324/324 [==============================] - 135s 418ms/step - loss: 1.2556 - val_loss: 1.8522\n","Epoch 21/30\n","324/324 [==============================] - 135s 417ms/step - loss: 1.1917 - val_loss: 1.8279\n","Epoch 22/30\n","324/324 [==============================] - 136s 419ms/step - loss: 1.1689 - val_loss: 1.8869\n","Epoch 23/30\n","324/324 [==============================] - 135s 416ms/step - loss: 1.1111 - val_loss: 1.8492\n"]}],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 128x128x16\n","\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 64x64x32\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Dense(2, activation='linear'))\n","\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index]\n","    y_train = targets[train_index]\n","    x_val = data[val_index]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= (x_val, y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.132283353805542\n","1.8107167959213257\n"]}],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]},{"cell_type":"markdown","metadata":{"id":"DTUa7a4-oU7C"},"source":["## Model takes inputs as gray images with landmarks concatenated at latent space"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"euy5aP_Tobvj"},"outputs":[],"source":["learning_rate = 0.001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/landmarksConcatenatedModel.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"-cuHTTH2ocCr"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","102/324 [========>.....................] - ETA: 2:13 - loss: 914.5102"]}],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    img_input = Input((64,64,1))\n","    landmarks_input = Input((64*64))\n","\n","    cnnLayers = Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,1), padding='same')(img_input)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","    cnnLayers = Conv2D(16, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    #Output dimension: 128x128x16\n","\n","    cnnLayers = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","    cnnLayers = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    #Output dimension: 64x64x32\n","\n","    flatten_layer = Flatten()(cnnLayers)\n","    \n","    concatenate_layer = concatenate([flatten_layer, landmarks_input])\n","    dense = Dense(512, activation='relu')(concatenate_layer)\n","    dense = Dropout(0.25)(dense)\n","\n","    dense = Dense(1024, activation='relu')(dense)\n","    dense = Dropout(0.4)(dense)\n","\n","    output = Dense(2, activation='linear')(dense)\n","\n","    model = Model(inputs=[img_input, landmarks_input], outputs=output)\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index]\n","    y_train = targets[train_index]\n","    x_val = data[val_index]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x=[x_train[:,:,:,0], np.reshape(x_train[:,:,:,1],((x_train.shape[0],64*64)))], y=y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= ([x_val[:,:,:,0], np.reshape(x_val[:,:,:,1],((x_val.shape[0],64*64)))], y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))\n","\n","plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
