{"cells":[{"cell_type":"markdown","metadata":{"id":"Y76axBV8GQo2"},"source":["## Import Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HXMjh8hNk9m"},"outputs":[],"source":["# List of external libraries used:\n","# pandas: https://pandas.pydata.org\n","# numpy: https://numpy.org\n","# matplotlub: https://matplotlib.org\n","# sklearn: https://scikit-learn.org"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1945,"status":"ok","timestamp":1648087550743,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"y42It3hMOFbe","outputId":"3372d661-967d-40d1-8ce9-e0b971472e51"},"outputs":[],"source":["# import os\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# os.chdir(\"drive/My Drive/Colab Notebooks/CMPT419Project/model\")"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13924,"status":"ok","timestamp":1648087564665,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"jhxzzOkz0fyX"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-26 13:45:15.965483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hvtruong/.local/lib/python3.8/site-packages/cv2/../../lib64:\n","2022-03-26 13:45:15.965533: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n","  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","\n","from sklearn.utils import shuffle\n","\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AvgPool2D, Input, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model"]},{"cell_type":"markdown","metadata":{"id":"jTuCSBCUGbx9"},"source":["# Preprocessing:"]},{"cell_type":"markdown","metadata":{},"source":["## Landmarks detection"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import dlib\n","\n","predictor = dlib.shape_predictor('../Dataset/utils/shape_predictor_68_face_landmarks.dat')\n","\n","def get_landmarks(face):\n","    landmarks = predictor(face, dlib.rectangle(0,0,63,63))\n","    landmarks_image = np.zeros((64,64))\n","    for i in range(0, 68):\n","        cv2.circle(landmarks_image, (landmarks.part(i).x, landmarks.part(i).y), 1, 255, 1)\n","  \n","    return landmarks_image"]},{"cell_type":"markdown","metadata":{},"source":["## Load the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":32332,"status":"ok","timestamp":1648087596983,"user":{"displayName":"Viet Truong Hoang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11282668789842064039"},"user_tz":420},"id":"LvMPiJ8kNk9s"},"outputs":[],"source":["import h5py\n","\n","filename = \"../Dataset/facial_data/facial_data.h5\"\n","\n","data = np.zeros((25844,64,64,2))\n","\n","with h5py.File(filename, \"r\") as f:\n","    keys = list(f.keys())\n","    # Get the data\n","    for i in range(int(len(keys))):\n","      data[i,:,:,0] = (np.array(f[keys[i]]))\n","      data[i,:,:,1] = (get_landmarks(np.array(f[keys[i]])))\n","\n","data = np.array(data)\n","\n","df = pd.read_csv('../Dataset/src_data/label_data.csv')\n","df = df[df['file_name'].isin(keys)]\n","targets = df[['arousal', 'valence']].values\n","\n","data, targets = shuffle(data, targets)"]},{"cell_type":"markdown","metadata":{"id":"wbIA_jMgNk9y"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"viqiqZskQe9W"},"source":["## Model take input as gray images"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["learning_rate = 0.0001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/grayImagesModel.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNWocgAuNk9y","outputId":"a11140eb-3d63-4c10-9b05-338f69e0c0ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","  3/324 [..............................] - ETA: 3:12 - loss: 9.6046"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2784/3156973931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 32x32x16\n","\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 16x16x32\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Dense(2, activation='linear'))\n","\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index][:,:,:,0]\n","    y_train = targets[train_index]\n","    x_val = data[val_index][:,:,:,0]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= (x_val, y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jbSh8y5Nk9z","outputId":"d83c9cb1-0801-409b-e1e6-6e0c66338276"},"outputs":[],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ju1K08ZBNk90","outputId":"9e3eae68-4b9e-463f-a282-841496a8a634"},"outputs":[],"source":["plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApVAp0TmNk91","outputId":"ef084cc5-fa39-4f1d-977b-fc96d66cdfe1"},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]},{"cell_type":"markdown","metadata":{"id":"jkLKmTOvoBUW"},"source":["## Model takes inputs as gray images with an addtional landmarks layer"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["learning_rate = 0.0001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/2layersInputModel_max.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-25 17:02:26.758769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hvtruong/.local/lib/python3.8/site-packages/cv2/../../lib64:\n","2022-03-25 17:02:26.758826: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-03-25 17:02:26.758850: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Viete): /proc/driver/nvidia/version does not exist\n","2022-03-25 17:02:26.759179: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-03-25 17:02:27.838868: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 189s 580ms/step - loss: 7.2752 - val_loss: 6.6888\n","Epoch 2/30\n","324/324 [==============================] - 144s 445ms/step - loss: 6.3234 - val_loss: 5.4736\n","Epoch 3/30\n","324/324 [==============================] - 127s 393ms/step - loss: 5.4880 - val_loss: 4.5677\n","Epoch 4/30\n","324/324 [==============================] - 152s 469ms/step - loss: 4.7094 - val_loss: 4.2227\n","Epoch 5/30\n","324/324 [==============================] - 142s 439ms/step - loss: 4.1884 - val_loss: 4.1393\n","Epoch 6/30\n","324/324 [==============================] - 130s 400ms/step - loss: 3.7798 - val_loss: 3.7576\n","Epoch 7/30\n","324/324 [==============================] - 153s 473ms/step - loss: 3.4699 - val_loss: 3.7024\n","Epoch 8/30\n","324/324 [==============================] - 139s 428ms/step - loss: 3.2285 - val_loss: 3.2966\n","Epoch 9/30\n","324/324 [==============================] - 139s 430ms/step - loss: 3.0251 - val_loss: 3.0453\n","Epoch 10/30\n","324/324 [==============================] - 138s 427ms/step - loss: 2.8512 - val_loss: 3.0250\n","Epoch 11/30\n","324/324 [==============================] - 142s 437ms/step - loss: 2.6759 - val_loss: 2.9329\n","Epoch 12/30\n","324/324 [==============================] - 137s 422ms/step - loss: 2.5468 - val_loss: 2.6680\n","Epoch 13/30\n","324/324 [==============================] - 132s 407ms/step - loss: 2.4530 - val_loss: 2.6630\n","Epoch 14/30\n","324/324 [==============================] - 118s 363ms/step - loss: 2.3646 - val_loss: 2.6732\n","Epoch 15/30\n","324/324 [==============================] - 118s 365ms/step - loss: 2.2407 - val_loss: 2.5151\n","Epoch 16/30\n","324/324 [==============================] - 119s 366ms/step - loss: 2.1680 - val_loss: 2.4907\n","Epoch 17/30\n","324/324 [==============================] - 118s 365ms/step - loss: 2.0915 - val_loss: 2.3655\n","Epoch 18/30\n","324/324 [==============================] - 119s 367ms/step - loss: 1.9953 - val_loss: 2.2404\n","Epoch 19/30\n","324/324 [==============================] - 118s 364ms/step - loss: 1.9286 - val_loss: 2.2659\n","Epoch 20/30\n","324/324 [==============================] - 118s 365ms/step - loss: 1.8198 - val_loss: 2.1453\n","Epoch 21/30\n","324/324 [==============================] - 119s 366ms/step - loss: 1.7878 - val_loss: 2.0884\n","Epoch 22/30\n","324/324 [==============================] - 119s 367ms/step - loss: 1.7269 - val_loss: 2.1763\n","Epoch 23/30\n","324/324 [==============================] - 119s 366ms/step - loss: 1.6795 - val_loss: 2.1350\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-25 17:53:26.896002: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 123s 377ms/step - loss: 7.4231 - val_loss: 6.9696\n","Epoch 2/30\n","324/324 [==============================] - 119s 366ms/step - loss: 6.7004 - val_loss: 5.9824\n","Epoch 3/30\n","324/324 [==============================] - 118s 363ms/step - loss: 6.0784 - val_loss: 5.1919\n","Epoch 4/30\n","324/324 [==============================] - 119s 366ms/step - loss: 5.3635 - val_loss: 4.5915\n","Epoch 5/30\n","324/324 [==============================] - 119s 367ms/step - loss: 4.7352 - val_loss: 3.9807\n","Epoch 6/30\n","324/324 [==============================] - 119s 366ms/step - loss: 4.1754 - val_loss: 3.8398\n","Epoch 7/30\n","324/324 [==============================] - 118s 364ms/step - loss: 3.8684 - val_loss: 3.4949\n","Epoch 8/30\n","324/324 [==============================] - 118s 365ms/step - loss: 3.5384 - val_loss: 3.1902\n","Epoch 9/30\n","324/324 [==============================] - 118s 365ms/step - loss: 3.3215 - val_loss: 3.0921\n","Epoch 10/30\n","324/324 [==============================] - 118s 365ms/step - loss: 3.0719 - val_loss: 2.8607\n","Epoch 11/30\n","324/324 [==============================] - 118s 364ms/step - loss: 2.9449 - val_loss: 2.8265\n","Epoch 12/30\n","324/324 [==============================] - 118s 363ms/step - loss: 2.7890 - val_loss: 2.6657\n","Epoch 13/30\n","324/324 [==============================] - 118s 364ms/step - loss: 2.6220 - val_loss: 2.6132\n","Epoch 14/30\n","324/324 [==============================] - 118s 365ms/step - loss: 2.5024 - val_loss: 2.4434\n","Epoch 15/30\n","324/324 [==============================] - 118s 364ms/step - loss: 2.3706 - val_loss: 2.4099\n","Epoch 16/30\n","324/324 [==============================] - 119s 367ms/step - loss: 2.2896 - val_loss: 2.3277\n","Epoch 17/30\n","324/324 [==============================] - 118s 364ms/step - loss: 2.1796 - val_loss: 2.2611\n","Epoch 18/30\n","324/324 [==============================] - 118s 364ms/step - loss: 2.0888 - val_loss: 2.2910\n","Epoch 19/30\n","324/324 [==============================] - 119s 366ms/step - loss: 2.0372 - val_loss: 2.2030\n","Epoch 20/30\n","324/324 [==============================] - 118s 366ms/step - loss: 1.9417 - val_loss: 2.1882\n","Epoch 21/30\n","324/324 [==============================] - 118s 365ms/step - loss: 1.8917 - val_loss: 2.1030\n","Epoch 22/30\n","324/324 [==============================] - 118s 363ms/step - loss: 1.8137 - val_loss: 2.0815\n","Epoch 23/30\n","324/324 [==============================] - 119s 368ms/step - loss: 1.7524 - val_loss: 2.0791\n","Epoch 24/30\n","324/324 [==============================] - 119s 367ms/step - loss: 1.6917 - val_loss: 2.0099\n","Epoch 25/30\n","324/324 [==============================] - 118s 363ms/step - loss: 1.6363 - val_loss: 2.0058\n","Epoch 26/30\n","324/324 [==============================] - 117s 361ms/step - loss: 1.6191 - val_loss: 1.9617\n","Epoch 27/30\n","324/324 [==============================] - 117s 363ms/step - loss: 1.5588 - val_loss: 1.9351\n","Epoch 28/30\n","324/324 [==============================] - 118s 363ms/step - loss: 1.4934 - val_loss: 2.0614\n","Epoch 29/30\n","324/324 [==============================] - 118s 363ms/step - loss: 1.4536 - val_loss: 1.9217\n","Epoch 30/30\n","324/324 [==============================] - 116s 359ms/step - loss: 1.4327 - val_loss: 1.9112\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-25 18:52:36.724968: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 120s 368ms/step - loss: 7.2661 - val_loss: 6.7578\n","Epoch 2/30\n","324/324 [==============================] - 118s 364ms/step - loss: 6.4694 - val_loss: 5.7161\n","Epoch 3/30\n","324/324 [==============================] - 118s 364ms/step - loss: 5.7291 - val_loss: 4.8048\n","Epoch 4/30\n","324/324 [==============================] - 118s 365ms/step - loss: 4.9955 - val_loss: 4.2804\n","Epoch 5/30\n","324/324 [==============================] - 118s 364ms/step - loss: 4.3690 - val_loss: 3.9816\n","Epoch 6/30\n","324/324 [==============================] - 118s 364ms/step - loss: 3.9782 - val_loss: 3.6558\n","Epoch 7/30\n","324/324 [==============================] - 118s 364ms/step - loss: 3.6125 - val_loss: 3.5783\n","Epoch 8/30\n","324/324 [==============================] - 118s 365ms/step - loss: 3.3364 - val_loss: 3.2209\n","Epoch 9/30\n","324/324 [==============================] - 119s 366ms/step - loss: 3.0917 - val_loss: 2.8938\n","Epoch 10/30\n","324/324 [==============================] - 118s 363ms/step - loss: 2.8955 - val_loss: 2.6784\n","Epoch 11/30\n","324/324 [==============================] - 118s 363ms/step - loss: 2.7346 - val_loss: 2.6828\n","Epoch 12/30\n","324/324 [==============================] - 118s 365ms/step - loss: 2.5884 - val_loss: 2.5424\n","Epoch 13/30\n","324/324 [==============================] - 119s 367ms/step - loss: 2.4282 - val_loss: 2.4759\n","Epoch 14/30\n","324/324 [==============================] - 119s 368ms/step - loss: 2.3816 - val_loss: 2.4024\n","Epoch 15/30\n","324/324 [==============================] - 119s 368ms/step - loss: 2.2195 - val_loss: 2.3787\n","Epoch 16/30\n","324/324 [==============================] - 120s 371ms/step - loss: 2.1028 - val_loss: 2.2388\n","Epoch 17/30\n","324/324 [==============================] - 119s 366ms/step - loss: 2.0309 - val_loss: 2.2150\n","Epoch 18/30\n","324/324 [==============================] - 118s 365ms/step - loss: 1.9337 - val_loss: 2.1887\n","Epoch 19/30\n","324/324 [==============================] - 118s 364ms/step - loss: 1.8641 - val_loss: 2.0949\n","Epoch 20/30\n","324/324 [==============================] - 118s 364ms/step - loss: 1.7854 - val_loss: 2.0637\n","Epoch 21/30\n","324/324 [==============================] - 119s 366ms/step - loss: 1.7400 - val_loss: 2.0706\n","Epoch 22/30\n","324/324 [==============================] - 119s 368ms/step - loss: 1.6790 - val_loss: 2.0344\n","Epoch 23/30\n","324/324 [==============================] - 118s 364ms/step - loss: 1.6087 - val_loss: 1.9440\n","Epoch 24/30\n","324/324 [==============================] - 120s 370ms/step - loss: 1.5505 - val_loss: 1.9758\n","Epoch 25/30\n","324/324 [==============================] - 119s 369ms/step - loss: 1.5165 - val_loss: 1.9335\n","Epoch 26/30\n","324/324 [==============================] - 119s 367ms/step - loss: 1.4550 - val_loss: 1.9179\n","Epoch 27/30\n","324/324 [==============================] - 118s 366ms/step - loss: 1.4039 - val_loss: 1.9238\n","Epoch 28/30\n","324/324 [==============================] - 119s 368ms/step - loss: 1.3606 - val_loss: 1.8891\n","Epoch 29/30\n","324/324 [==============================] - 119s 368ms/step - loss: 1.3539 - val_loss: 1.8798\n","Epoch 30/30\n","324/324 [==============================] - 120s 369ms/step - loss: 1.3069 - val_loss: 1.8462\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-25 19:52:01.089912: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677478400 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 123s 377ms/step - loss: 7.3881 - val_loss: 7.1187\n","Epoch 2/30\n","324/324 [==============================] - 122s 377ms/step - loss: 6.6514 - val_loss: 5.9731\n","Epoch 3/30\n","324/324 [==============================] - 122s 377ms/step - loss: 5.9654 - val_loss: 5.1520\n","Epoch 4/30\n","324/324 [==============================] - 122s 376ms/step - loss: 5.2465 - val_loss: 4.4295\n","Epoch 5/30\n","324/324 [==============================] - 122s 376ms/step - loss: 4.6598 - val_loss: 4.0395\n","Epoch 6/30\n","324/324 [==============================] - 121s 374ms/step - loss: 4.1839 - val_loss: 3.5428\n","Epoch 7/30\n","324/324 [==============================] - 122s 377ms/step - loss: 3.8112 - val_loss: 3.3972\n","Epoch 8/30\n","324/324 [==============================] - 122s 378ms/step - loss: 3.5392 - val_loss: 3.0820\n","Epoch 9/30\n","324/324 [==============================] - 123s 380ms/step - loss: 3.2775 - val_loss: 2.8305\n","Epoch 10/30\n","324/324 [==============================] - 122s 376ms/step - loss: 3.0501 - val_loss: 2.8275\n","Epoch 11/30\n","324/324 [==============================] - 122s 376ms/step - loss: 2.8976 - val_loss: 2.5885\n","Epoch 12/30\n","324/324 [==============================] - 122s 378ms/step - loss: 2.7180 - val_loss: 2.5502\n","Epoch 13/30\n","324/324 [==============================] - 122s 376ms/step - loss: 2.5838 - val_loss: 2.5285\n","Epoch 14/30\n","324/324 [==============================] - 122s 376ms/step - loss: 2.4814 - val_loss: 2.3907\n","Epoch 15/30\n","324/324 [==============================] - 122s 377ms/step - loss: 2.3493 - val_loss: 2.3521\n","Epoch 16/30\n","324/324 [==============================] - 123s 379ms/step - loss: 2.2614 - val_loss: 2.2883\n","Epoch 17/30\n","324/324 [==============================] - 123s 380ms/step - loss: 2.1481 - val_loss: 2.2061\n","Epoch 18/30\n","324/324 [==============================] - 122s 377ms/step - loss: 2.0475 - val_loss: 2.1567\n","Epoch 19/30\n","324/324 [==============================] - 123s 379ms/step - loss: 1.9677 - val_loss: 2.1804\n","Epoch 20/30\n","324/324 [==============================] - 123s 380ms/step - loss: 1.9239 - val_loss: 2.0920\n","Epoch 21/30\n","324/324 [==============================] - 123s 379ms/step - loss: 1.8318 - val_loss: 2.0787\n","Epoch 22/30\n","324/324 [==============================] - 122s 376ms/step - loss: 1.7669 - val_loss: 2.0215\n","Epoch 23/30\n","324/324 [==============================] - 122s 376ms/step - loss: 1.7265 - val_loss: 2.0385\n","Epoch 24/30\n","324/324 [==============================] - 124s 382ms/step - loss: 1.6718 - val_loss: 2.0031\n","Epoch 25/30\n","324/324 [==============================] - 123s 380ms/step - loss: 1.5887 - val_loss: 1.9484\n","Epoch 26/30\n","324/324 [==============================] - 123s 380ms/step - loss: 1.5613 - val_loss: 1.9636\n","Epoch 27/30\n","324/324 [==============================] - 122s 377ms/step - loss: 1.5081 - val_loss: 1.9244\n","Epoch 28/30\n","324/324 [==============================] - 122s 377ms/step - loss: 1.4452 - val_loss: 1.9205\n","Epoch 29/30\n","324/324 [==============================] - 123s 379ms/step - loss: 1.4215 - val_loss: 1.9853\n","Epoch 30/30\n","324/324 [==============================] - 123s 380ms/step - loss: 1.4094 - val_loss: 1.9189\n"]},{"name":"stderr","output_type":"stream","text":["2022-03-25 20:53:18.058645: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 677511168 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 122s 374ms/step - loss: 7.4329 - val_loss: 6.8953\n","Epoch 2/30\n","324/324 [==============================] - 120s 370ms/step - loss: 6.6055 - val_loss: 5.7711\n","Epoch 3/30\n","324/324 [==============================] - 120s 370ms/step - loss: 5.8380 - val_loss: 4.9757\n","Epoch 4/30\n","324/324 [==============================] - 121s 372ms/step - loss: 5.1354 - val_loss: 4.3881\n","Epoch 5/30\n","324/324 [==============================] - 121s 373ms/step - loss: 4.5287 - val_loss: 4.0356\n","Epoch 6/30\n","324/324 [==============================] - 121s 372ms/step - loss: 4.0751 - val_loss: 3.7621\n","Epoch 7/30\n","324/324 [==============================] - 121s 373ms/step - loss: 3.7236 - val_loss: 3.2632\n","Epoch 8/30\n","324/324 [==============================] - 121s 374ms/step - loss: 3.4419 - val_loss: 3.1916\n","Epoch 9/30\n","324/324 [==============================] - 121s 374ms/step - loss: 3.1591 - val_loss: 3.2153\n","Epoch 10/30\n","324/324 [==============================] - 121s 372ms/step - loss: 2.9938 - val_loss: 3.0061\n","Epoch 11/30\n","324/324 [==============================] - 125s 385ms/step - loss: 2.8115 - val_loss: 2.7517\n","Epoch 12/30\n","324/324 [==============================] - 133s 412ms/step - loss: 2.6520 - val_loss: 2.6770\n","Epoch 13/30\n","324/324 [==============================] - 129s 399ms/step - loss: 2.5508 - val_loss: 2.5763\n","Epoch 14/30\n","324/324 [==============================] - 129s 398ms/step - loss: 2.4029 - val_loss: 2.4831\n","Epoch 15/30\n","324/324 [==============================] - 129s 398ms/step - loss: 2.2996 - val_loss: 2.3942\n","Epoch 16/30\n","324/324 [==============================] - 130s 401ms/step - loss: 2.1918 - val_loss: 2.2899\n","Epoch 17/30\n","324/324 [==============================] - 132s 407ms/step - loss: 2.0928 - val_loss: 2.3974\n","Epoch 18/30\n","324/324 [==============================] - 120s 370ms/step - loss: 2.0442 - val_loss: 2.1857\n","Epoch 19/30\n","324/324 [==============================] - 119s 369ms/step - loss: 1.9699 - val_loss: 2.1895\n","Epoch 20/30\n","324/324 [==============================] - 119s 366ms/step - loss: 1.8616 - val_loss: 2.2432\n"]}],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(16, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 128x128x16\n","\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    model.add(AvgPool2D(strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    #Output dimension: 64x64x32\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.4))\n","\n","    model.add(Dense(2, activation='linear'))\n","\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index]\n","    y_train = targets[train_index]\n","    x_val = data[val_index]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= (x_val, y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.5380261659622192\n","2.0109084606170655\n"]}],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]},{"cell_type":"markdown","metadata":{"id":"DTUa7a4-oU7C"},"source":["## Model takes inputs as gray images with landmarks concatenated at latent space"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"euy5aP_Tobvj"},"outputs":[],"source":["learning_rate = 0.001\n","epochs = 30\n","batch_size = 64\n","\n","callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n","             ModelCheckpoint(filepath='../models/landmarksConcatenatedModel.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-cuHTTH2ocCr"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-24 17:19:54.518036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/hvtruong/.local/lib/python3.8/site-packages/cv2/../../lib64:\n","2022-03-24 17:19:54.518120: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-03-24 17:19:54.518151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Viete): /proc/driver/nvidia/version does not exist\n","2022-03-24 17:19:54.518792: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","324/324 [==============================] - 177s 543ms/step - loss: 244.3669 - val_loss: 7.7922\n","Epoch 2/30\n","324/324 [==============================] - 175s 541ms/step - loss: 8.6216 - val_loss: 6.9578\n","Epoch 3/30\n","324/324 [==============================] - 175s 539ms/step - loss: 8.2960 - val_loss: 6.9155\n","Epoch 4/30\n","324/324 [==============================] - 175s 539ms/step - loss: 7.8737 - val_loss: 6.8936\n","Epoch 5/30\n","324/324 [==============================] - 166s 513ms/step - loss: 7.6889 - val_loss: 6.8653\n","Epoch 6/30\n","324/324 [==============================] - 136s 419ms/step - loss: 9.2975 - val_loss: 6.8719\n","Epoch 7/30\n","324/324 [==============================] - 137s 423ms/step - loss: 8.1785 - val_loss: 6.8568\n","Epoch 8/30\n","324/324 [==============================] - 141s 435ms/step - loss: 9.1855 - val_loss: 6.8221\n","Epoch 9/30\n","324/324 [==============================] - 138s 425ms/step - loss: 7.2914 - val_loss: 6.8967\n","Epoch 10/30\n","324/324 [==============================] - 138s 426ms/step - loss: 7.6063 - val_loss: 6.8924\n","Epoch 1/30\n","324/324 [==============================] - 141s 432ms/step - loss: 184.0845 - val_loss: 8.0858\n","Epoch 2/30\n","324/324 [==============================] - 137s 424ms/step - loss: 8.8571 - val_loss: 7.2252\n","Epoch 3/30\n","324/324 [==============================] - 137s 421ms/step - loss: 8.2294 - val_loss: 7.0767\n","Epoch 4/30\n","324/324 [==============================] - 136s 421ms/step - loss: 8.2813 - val_loss: 6.9960\n","Epoch 5/30\n","324/324 [==============================] - 136s 421ms/step - loss: 9.4993 - val_loss: 7.0971\n","Epoch 6/30\n","324/324 [==============================] - 137s 423ms/step - loss: 8.3553 - val_loss: 7.2956\n","Epoch 1/30\n","324/324 [==============================] - 139s 427ms/step - loss: 316.2366 - val_loss: 8.7357\n","Epoch 2/30\n","324/324 [==============================] - 166s 514ms/step - loss: 9.2637 - val_loss: 7.3933\n","Epoch 3/30\n","324/324 [==============================] - 147s 454ms/step - loss: 7.9949 - val_loss: 7.1200\n","Epoch 4/30\n","324/324 [==============================] - 144s 443ms/step - loss: 7.5482 - val_loss: 7.0616\n","Epoch 5/30\n","324/324 [==============================] - 146s 451ms/step - loss: 7.2855 - val_loss: 7.0303\n","Epoch 6/30\n","324/324 [==============================] - 182s 560ms/step - loss: 7.3023 - val_loss: 7.0113\n","Epoch 7/30\n","324/324 [==============================] - 180s 555ms/step - loss: 7.2210 - val_loss: 7.0594\n","Epoch 8/30\n","324/324 [==============================] - 156s 482ms/step - loss: 7.1493 - val_loss: 7.0812\n","Epoch 1/30\n","324/324 [==============================] - 186s 573ms/step - loss: 396.1555 - val_loss: 9.5351\n","Epoch 2/30\n","324/324 [==============================] - 144s 446ms/step - loss: 9.9323 - val_loss: 8.2123\n","Epoch 3/30\n","324/324 [==============================] - 155s 480ms/step - loss: 9.2944 - val_loss: 7.5051\n","Epoch 4/30\n","324/324 [==============================] - 162s 502ms/step - loss: 7.8941 - val_loss: 7.2505\n","Epoch 5/30\n","324/324 [==============================] - 202s 623ms/step - loss: 8.6526 - val_loss: 7.2897\n","Epoch 6/30\n","324/324 [==============================] - 188s 580ms/step - loss: 10.6438 - val_loss: 7.3547\n","Epoch 1/30\n","324/324 [==============================] - 182s 554ms/step - loss: 323.9256 - val_loss: 8.3855\n","Epoch 2/30\n","324/324 [==============================] - 150s 462ms/step - loss: 8.9995 - val_loss: 7.1702\n","Epoch 3/30\n","324/324 [==============================] - 153s 472ms/step - loss: 7.7864 - val_loss: 6.9891\n","Epoch 4/30\n","324/324 [==============================] - 151s 464ms/step - loss: 8.0302 - val_loss: 6.9708\n","Epoch 5/30\n","324/324 [==============================] - 151s 467ms/step - loss: 8.3664 - val_loss: 6.9704\n","Epoch 6/30\n","324/324 [==============================] - 151s 465ms/step - loss: 8.7396 - val_loss: 6.9557\n","Epoch 7/30\n","324/324 [==============================] - 152s 468ms/step - loss: 8.4040 - val_loss: 6.9411\n","Epoch 8/30\n","324/324 [==============================] - 149s 461ms/step - loss: 7.9642 - val_loss: 7.0018\n","Epoch 9/30\n","324/324 [==============================] - 150s 462ms/step - loss: 13.0650 - val_loss: 6.9451\n"]}],"source":["kf = KFold(n_splits=5)\n","\n","loss = []\n","val_loss = []\n","\n","for train_index, val_index in kf.split(data):\n","\n","    img_input = Input((64,64,1))\n","    landmarks_input = Input((64*64))\n","\n","    cnnLayers = Conv2D(16, kernel_size=(3,3), activation='relu',input_shape=(64,64,1), padding='same')(img_input)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","    cnnLayers = Conv2D(16, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    #Output dimension: 128x128x16\n","\n","    cnnLayers = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","    cnnLayers = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(cnnLayers)\n","    cnnLayers = BatchNormalization()(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    cnnLayers = AvgPool2D(strides=(2,2))(cnnLayers)\n","    cnnLayers = Dropout(0.25)(cnnLayers)\n","\n","    #model.add(MaxPool2D(strides=(2,2)))\n","    #Output dimension: 64x64x32\n","\n","    flatten_layer = Flatten()(cnnLayers)\n","    \n","    concatenate_layer = concatenate([flatten_layer, landmarks_input])\n","    dense = Dense(512, activation='relu')(concatenate_layer)\n","    dense = Dropout(0.25)(dense)\n","\n","    dense = Dense(1024, activation='relu')(dense)\n","    dense = Dropout(0.4)(dense)\n","\n","    output = Dense(2, activation='linear')(dense)\n","\n","    model = Model(inputs=[img_input, landmarks_input], outputs=output)\n","    model.compile(loss = 'mse', optimizer = Adam(learning_rate))\n","\n","    x_train = data[train_index]\n","    y_train = targets[train_index]\n","    x_val = data[val_index]\n","    y_val = targets[val_index]\n","\n","    history = model.fit(x=[x_train[:,:,:,0], np.reshape(x_train[:,:,:,1],((x_train.shape[0],64*64)))], y=y_train, epochs=epochs, batch_size=batch_size, callbacks=[callbacks], verbose=1, validation_data= ([x_val[:,:,:,0], np.reshape(x_val[:,:,:,1],((x_val.shape[0],64*64)))], y_val))\n","\n","    loss.append(history.history['loss'][-1])\n","    val_loss.append(history.history['val_loss'][-1])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["9.363943958282471\n","7.113777732849121\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x360 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["print(np.mean(loss))\n","print(np.mean(val_loss))\n","\n","plt.figure(figsize=(6, 5))\n","# training loss\n","plt.plot(history.history['loss'], color='r')\n","#validation loss\n","plt.plot(history.history['val_loss'], color='g')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(x_val)\n","for rand_num in np.random.randint(0, len(y_val), 10):\n","    plt.figure()\n","    plt.imshow(x_val[rand_num].reshape(48, 48),cmap='gray')\n","    plt.axis('off')\n","    plt.title('Prediction: ' + str(y_pred[rand_num]) + ' Real: ' + str(y_val[rand_num]), color='g')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
